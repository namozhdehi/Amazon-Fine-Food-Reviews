{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26321bf5",
   "metadata": {},
   "source": [
    "# 2 Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea05173",
   "metadata": {},
   "source": [
    "## 2.1 Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19293835",
   "metadata": {},
   "source": [
    "## 2.2 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2bd30",
   "metadata": {},
   "source": [
    "Data wrangling is the process of cleaning, transforming, and organizing raw data into a usable format. Below are the steps for performing data wrangling on the \"Amazon Fine Food Reviews\" dataset with the columns Id, ProductId, UserId, ProfileName, HelpfulnessNumerator, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d42938",
   "metadata": {},
   "source": [
    "### 2.2.1 Data Science Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5dc4f",
   "metadata": {},
   "source": [
    "The \"Amazon Fine Food Reviews\" dataset offers valuable insights into customer sentiment and preferences through product reviews. By applying natural language processing (NLP) and machine learning techniques, the challenge is to analyze review texts, ratings, and other attributes to identify patterns and trends in customer feedback. This will help uncover key themes related to product quality, delivery experience, and overall satisfaction. The goal is to provide actionable insights for improving product offerings, enhancing customer service, and informing marketing strategies, ultimately leading to better customer understanding and increased loyalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d646c28",
   "metadata": {},
   "source": [
    "## 2.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dff0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sqlite3\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2422ef",
   "metadata": {},
   "source": [
    "## 2.4 Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00223e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191c3392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews\"\"\", con)\n",
    "amazon_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177d7f8",
   "metadata": {},
   "source": [
    "## 2.5 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7530322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                        0\n",
      "ProductId                 0\n",
      "UserId                    0\n",
      "ProfileName               0\n",
      "HelpfulnessNumerator      0\n",
      "HelpfulnessDenominator    0\n",
      "Score                     0\n",
      "Time                      0\n",
      "Summary                   0\n",
      "Text                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = amazon_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Example: Fill missing values in 'ProfileName' with 'Unknown'\n",
    "amazon_data['ProfileName'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop rows where 'Text' is missing, as text data is crucial\n",
    "amazon_data.dropna(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686f42c",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28266d7d",
   "metadata": {},
   "source": [
    "## 2.6 Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5cde6",
   "metadata": {},
   "source": [
    "### 2.6.1 Duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4b0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to check for duplicates, excluding 'Id'\n",
    "columns_to_check = [col for col in amazon_data.columns if col != 'Id']\n",
    "\n",
    "# Check for duplicate records based on all columns except 'Id'\n",
    "duplicate_records = amazon_data[amazon_data.duplicated(subset=columns_to_check, keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f0f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>6517</td>\n",
       "      <td>B005O8BLLU</td>\n",
       "      <td>APH7I7OZ8WUJP</td>\n",
       "      <td>J. Simpson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Great first food</td>\n",
       "      <td>This is excellent for a baby's first taste. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>6518</td>\n",
       "      <td>B005O8BLLU</td>\n",
       "      <td>APH7I7OZ8WUJP</td>\n",
       "      <td>J. Simpson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Great first food</td>\n",
       "      <td>This is excellent for a baby's first taste. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>8523</td>\n",
       "      <td>B003VXFK44</td>\n",
       "      <td>A10H24TDLK2VDP</td>\n",
       "      <td>William Jens Jensen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1309824000</td>\n",
       "      <td>Unremarkable</td>\n",
       "      <td>First, let me say that I prefer extra-bold K-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>8524</td>\n",
       "      <td>B003VXFK44</td>\n",
       "      <td>A10H24TDLK2VDP</td>\n",
       "      <td>William Jens Jensen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1309824000</td>\n",
       "      <td>Unremarkable</td>\n",
       "      <td>First, let me say that I prefer extra-bold K-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9232</td>\n",
       "      <td>B006N3IG4K</td>\n",
       "      <td>A10H24TDLK2VDP</td>\n",
       "      <td>William Jens Jensen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1309824000</td>\n",
       "      <td>Unremarkable</td>\n",
       "      <td>First, let me say that I prefer extra-bold K-C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId          ProfileName  \\\n",
       "6516  6517  B005O8BLLU   APH7I7OZ8WUJP           J. Simpson   \n",
       "6517  6518  B005O8BLLU   APH7I7OZ8WUJP           J. Simpson   \n",
       "8522  8523  B003VXFK44  A10H24TDLK2VDP  William Jens Jensen   \n",
       "8523  8524  B003VXFK44  A10H24TDLK2VDP  William Jens Jensen   \n",
       "9231  9232  B006N3IG4K  A10H24TDLK2VDP  William Jens Jensen   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "6516                     0                       0      5  1347494400   \n",
       "6517                     0                       0      5  1347494400   \n",
       "8522                     0                       0      3  1309824000   \n",
       "8523                     0                       0      3  1309824000   \n",
       "9231                     0                       0      3  1309824000   \n",
       "\n",
       "               Summary                                               Text  \n",
       "6516  Great first food  This is excellent for a baby's first taste. Th...  \n",
       "6517  Great first food  This is excellent for a baby's first taste. Th...  \n",
       "8522      Unremarkable  First, let me say that I prefer extra-bold K-C...  \n",
       "8523      Unremarkable  First, let me say that I prefer extra-bold K-C...  \n",
       "9231      Unremarkable  First, let me say that I prefer extra-bold K-C...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9373e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_records.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab521a3",
   "metadata": {},
   "source": [
    "There are a total of 506 duplicate records identified in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe4c0e",
   "metadata": {},
   "source": [
    "### 2.6.1 Duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258e0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store non-duplicate records\n",
    "non_duplicate_records = amazon_data.drop_duplicates(keep=False)\n",
    "\n",
    "# Check for duplicate records based on ProductId, UserId, and ProfileName\n",
    "duplicate_reviews = non_duplicate_records[non_duplicate_records.duplicated(subset=['ProductId', 'UserId', 'ProfileName', 'Time'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0aa63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>426</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A1Y3XPZK9ZADFW</td>\n",
       "      <td>albinocrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1334016000</td>\n",
       "      <td>glad to find them in 1 oz size</td>\n",
       "      <td>I buy mostly for vending, so the size of the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>427</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A1Y3XPZK9ZADFW</td>\n",
       "      <td>albinocrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1334016000</td>\n",
       "      <td>pretty good, could be better</td>\n",
       "      <td>Glad to find these in a one ounce size but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>435</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A15USNEAJUXOSH</td>\n",
       "      <td>L. Schrank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1326067200</td>\n",
       "      <td>Quite good</td>\n",
       "      <td>I enjoy these chips. I got these instead of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A15USNEAJUXOSH</td>\n",
       "      <td>L. Schrank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1326067200</td>\n",
       "      <td>Delicious</td>\n",
       "      <td>I love these chips, I buy the 24 pack once a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>463</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A3RMGIKUWGPZOK</td>\n",
       "      <td>Jean Visnefski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1245024000</td>\n",
       "      <td>One of Their Best Flavors</td>\n",
       "      <td>Kettle Chips flavors can be hit or miss.  Some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   ProductId          UserId     ProfileName  HelpfulnessNumerator  \\\n",
       "425  426  B000G6RYNE  A1Y3XPZK9ZADFW      albinocrow                     0   \n",
       "426  427  B000G6RYNE  A1Y3XPZK9ZADFW      albinocrow                     0   \n",
       "434  435  B000G6RYNE  A15USNEAJUXOSH      L. Schrank                     0   \n",
       "435  436  B000G6RYNE  A15USNEAJUXOSH      L. Schrank                     0   \n",
       "462  463  B000G6RYNE  A3RMGIKUWGPZOK  Jean Visnefski                     0   \n",
       "\n",
       "     HelpfulnessDenominator  Score        Time  \\\n",
       "425                       0      4  1334016000   \n",
       "426                       0      4  1334016000   \n",
       "434                       0      4  1326067200   \n",
       "435                       0      5  1326067200   \n",
       "462                       0      5  1245024000   \n",
       "\n",
       "                            Summary  \\\n",
       "425  glad to find them in 1 oz size   \n",
       "426    pretty good, could be better   \n",
       "434                      Quite good   \n",
       "435                       Delicious   \n",
       "462       One of Their Best Flavors   \n",
       "\n",
       "                                                  Text  \n",
       "425  I buy mostly for vending, so the size of the b...  \n",
       "426  Glad to find these in a one ounce size but the...  \n",
       "434  I enjoy these chips. I got these instead of my...  \n",
       "435  I love these chips, I buy the 24 pack once a m...  \n",
       "462  Kettle Chips flavors can be hit or miss.  Some...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ec4f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7424, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a2e45",
   "metadata": {},
   "source": [
    "There are 7,424 duplicate reviews in the dataset for the same product (identified by ProductId), submitted by the same user (identified by UserId) at the same time (identified by Time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cd060",
   "metadata": {},
   "source": [
    "## 2.6 Creating a Helpfulness Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39840823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for the helpfulness ratio\n",
    "amazon_data['HelpfulnessRatio'] = amazon_data['HelpfulnessNumerator'] / amazon_data['HelpfulnessDenominator']\n",
    "\n",
    "# Handle division by zero and missing values by filling with 0\n",
    "amazon_data['HelpfulnessRatio'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0587a1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    303826\n",
       "1.000000    183309\n",
       "0.500000     21623\n",
       "0.666667     10514\n",
       "0.750000      6364\n",
       "             ...  \n",
       "0.946237         1\n",
       "0.232558         1\n",
       "0.704545         1\n",
       "0.161290         1\n",
       "0.991411         1\n",
       "Name: HelpfulnessRatio, Length: 951, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data['HelpfulnessRatio'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab83f2a",
   "metadata": {},
   "source": [
    "The output shows the distribution of the HelpfulnessRatio in the amazon_data DataFrame. The data reveals that a significant number of reviews are marked as either completely unhelpful (0.0) or entirely helpful (1.0), with counts of 303,826 and 183,309 respectively. Intermediate values, such as 0.5, 0.67, and 0.75, appear less frequently, indicating some reviews receive mixed feedback. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2c37d",
   "metadata": {},
   "source": [
    "## 2.7 Converting Time to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fadd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Time column to datetime\n",
    "amazon_data['ReviewTime'] = pd.to_datetime(amazon_data['Time'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b81c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-10-16    1143\n",
       "2011-11-25    1088\n",
       "2011-11-28    1070\n",
       "2012-09-06    1018\n",
       "2012-08-06     989\n",
       "              ... \n",
       "2004-09-20       1\n",
       "2004-12-10       1\n",
       "2004-03-26       1\n",
       "2004-06-20       1\n",
       "2003-11-25       1\n",
       "Name: ReviewTime, Length: 3168, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data['ReviewTime'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a495ab4",
   "metadata": {},
   "source": [
    "October 16, 2012, has the highest frequency of customer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7101c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest review times 1999-10-08 00:00:00 and the latest review times 2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print('The earliest review times', amazon_data['ReviewTime'].min(), 'and the latest review times', amazon_data['ReviewTime'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d2787",
   "metadata": {},
   "source": [
    "## 2.8 Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5d470d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the Text and Summary columns\n",
    "amazon_data['CleanedText'] = amazon_data['Text'].apply(clean_text)\n",
    "amazon_data['CleanedSummary'] = amazon_data['Summary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6dc942",
   "metadata": {},
   "source": [
    "The preprocessing of text data converts the 'Text' and 'Summary' columns in the amazon_data dataframe to lowercase, and removes digits, punctuation, extra spaces, and leading/trailing spaces to create cleaned versions of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019c745",
   "metadata": {},
   "source": [
    "## 2.9 Tokenization and Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure you have the stopwords and punkt data downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to tokenize and remove stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize_text function to the CleanedText and CleanedSummary columns\n",
    "amazon_data['TokenizedText'] = amazon_data['CleanedText'].apply(tokenize_text)\n",
    "amazon_data['TokenizedSummary'] = amazon_data['CleanedSummary'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdc6a3",
   "metadata": {},
   "source": [
    "he code tokenizes the cleaned text data from the 'CleanedText' and 'CleanedSummary' columns in the amazon_data dataframe and removes stopwords, creating tokenized versions of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fead6",
   "metadata": {},
   "source": [
    "## 2.10 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fe6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Apply the lemmatize_tokens function to the TokenizedText and TokenizedSummary columns\n",
    "amazon_data['LemmatizedText'] = amazon_data['TokenizedText'].apply(lemmatize_tokens)\n",
    "amazon_data['LemmatizedSummary'] = amazon_data['TokenizedSummary'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac23e59",
   "metadata": {},
   "source": [
    "The code lemmatizes the tokenized text data from the 'TokenizedText' and 'TokenizedSummary' columns in the amazon_data dataframe, creating lemmatized versions of these columns to ensure words are reduced to their base or root form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d85e6",
   "metadata": {},
   "source": [
    "## 2.11 Saving the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69581553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>HelpfulnessRatio</th>\n",
       "      <th>ReviewTime</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>CleanedSummary</th>\n",
       "      <th>TokenizedText</th>\n",
       "      <th>TokenizedSummary</th>\n",
       "      <th>LemmatizedText</th>\n",
       "      <th>LemmatizedSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[good, quality, dog, food]</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[good, quality, dog, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[advertised]</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[advertised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[delight, says]</td>\n",
       "      <td>[confection, around, century, light, pillowy, ...</td>\n",
       "      <td>[delight, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[cough, medicine]</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[cough, medicine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>great taffy at a great price there was a wide ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffy]</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   HelpfulnessRatio ReviewTime  \\\n",
       "0               1.0 2011-04-27   \n",
       "1               0.0 2012-09-07   \n",
       "2               1.0 2008-08-18   \n",
       "3               1.0 2011-06-13   \n",
       "4               0.0 2012-10-21   \n",
       "\n",
       "                                         CleanedText         CleanedSummary  \\\n",
       "0  i have bought several of the vitality canned d...  good quality dog food   \n",
       "1  product arrived labeled as jumbo salted peanut...      not as advertised   \n",
       "2  this is a confection that has been around a fe...    delight says it all   \n",
       "3  if you are looking for the secret ingredient i...         cough medicine   \n",
       "4  great taffy at a great price there was a wide ...            great taffy   \n",
       "\n",
       "                                       TokenizedText  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, centuries, light, pillowy...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "             TokenizedSummary  \\\n",
       "0  [good, quality, dog, food]   \n",
       "1                [advertised]   \n",
       "2             [delight, says]   \n",
       "3           [cough, medicine]   \n",
       "4              [great, taffy]   \n",
       "\n",
       "                                      LemmatizedText  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, century, light, pillowy, ...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "            LemmatizedSummary  \n",
       "0  [good, quality, dog, food]  \n",
       "1                [advertised]  \n",
       "2              [delight, say]  \n",
       "3           [cough, medicine]  \n",
       "4              [great, taffy]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d45c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "amazon_data.to_csv('amazon_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd067b8",
   "metadata": {},
   "source": [
    "## 2.12 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9291dde",
   "metadata": {},
   "source": [
    "The above steps provide a comprehensive guide for wrangling the amazon_data DataFrame. The process includes handling missing values, creating new features, preprocessing text data, tokenizing and lemmatizing, encoding categorical variables, and saving the cleaned data. This ensures the dataset is in a usable format for further analysis and modeling tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
